version: "3.8"

services:
  airflow-init:
    image: apache/airflow:2.8.1
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    env_file:
      - .env
    entrypoint: >
      bash -c "airflow db init &&
               airflow users create --username $AIRFLOW_USER --password $AIRFLOW_PASSWORD --firstname $AIRFLOW_FIRSTNAME --lastname $AIRFLOW_LASTNAME --role Admin --email $AIRFLOW_EMAIL"
    volumes:
      - ./airflow/db:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - ml-network

  airflow:
    image: apache/airflow:2.8.1
    restart: always
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    env_file:
      - .env
    command: webserver
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/db:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - ml-network

  airflow-scheduler:
    image: apache/airflow:2.8.1
    restart: always
    depends_on:
      - airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
    env_file:
      - .env
    command: scheduler
    volumes:
      - ./airflow/db:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - ml-network

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.1
    command: mlflow server --backend-store-uri /mlflow/mlruns --host 0.0.0.0 --port 5000
    ports:
      - "5050:5000"
    volumes:
      - mlflow-artifacts:/mlflow/mlruns
    networks:
      - ml-network

  trainer:
    build:
      context: .
      dockerfile: Dockerfile.train
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    volumes:
      - mlflow-artifacts:/mlflow/mlruns
    networks:
      - ml-network

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    depends_on:
      - mlflow
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - mlflow-artifacts:/mlflow/mlruns
    networks:
      - ml-network

volumes:
  mlflow-artifacts:

networks:
  ml-network:
    driver: bridge
